\documentclass[letterpaper, 12pt]{math}

\title{Linear Algebra}
\author{Alvin Lin}
\date{August 2017 - December 2017}

\begin{document}

\maketitle

\section*{Subspaces}
Consider \( \R^n \). Let \( S\subseteq\R^n \). \( S \) is a \textbf{subspace}
of \( \R^n \) if:
\begin{enumerate}
  \item \( \vec{0}\in S \)
  \item If \( \vec{u},\vec{v}\in S \), then \( \vec{u}+\vec{v}\in S \).
  (Additive Closure)
  \item If \( \vec{u}\in S \) and \( c \) is a scalar, \( c\vec{u}\in S \).
  (Closure over Scalar Multiple)
\end{enumerate}
Consider \( S = \{\vec{0}\} \). Is \( S \) a subspace of \( \R^n \)?
\begin{enumerate}
  \item \( \vec{0}\in S \)
  \item \( \vec{0}+\vec{0} = \vec{0} \quad \vec{0}\in S \)
  \item \( c\vec{0} = \vec{0} \quad \vec{0}\in S \)
\end{enumerate}
\( \therefore S = \{\vec{0}\} \) is a subspace of \( \R^n \).

\subsubsection*{Example}
Let \( P \) be a plane through the origin. Show \( P \) is a subspace of
\( \R^3 \).
\[ P = span(\vec{v},\vec{w}) \]
\begin{enumerate}
  \item \( 0\vec{v}+0\vec{w} = \vec{0}\in P \)
  \item Additive Closure:
  \begin{align*}
    \vec{\alpha_1} &= c_1\vec{v}+c_2\vec{w}\in P \\
    \vec{\alpha_2} &= d_1\vec{v}+d_2\vec{w}\in P \\
    \vec{\alpha_1}+\vec{\alpha_2} &= (c_1+d_1)\vec{v}+(c_2+d_2)\vec{w}\in P
  \end{align*}
  \item Closure over Scalar Multiple:
  \begin{align*}
    \vec{\alpha} &= c_1\vec{v}+c_2\vec{w}\in P \\
    c\vec{\alpha} &= c(c_1\vec{v}+c_2\vec{w}) \\
    &= (cc_1)\vec{v}+(cc_2)\vec{w}\in P
  \end{align*}
\end{enumerate}
So \( P\subseteq\R^3 \)

\subsection*{Theorem}
In \( \R^n \), \( span(\vec{v_1},\dots,\vec{v_m}) \) is a subspace of
\( \R^n \). Non-example, consider:
\[ S = \left\{\begin{bmatrix}x \\ y \\ z\end{bmatrix}: x = 3y+1, z = 2y
  \right\} \]
Is \( S \) a subspace of \( \R^3 \)?
\[ \begin{bmatrix}0 \\ 0 \\ 0\end{bmatrix} =
  \begin{bmatrix}x \\ y \\ z\end{bmatrix} =
  \begin{bmatrix}3y+1 \\ y \\ 2y\end{bmatrix} \]
Thus \( \vec{0}\notin S \). \( S \) is not a subspace of \( \R^3 \).

\subsection*{Subspaces Associated with Matrices}
Let \( A \) be an \( m\times n \) matrix.
\begin{enumerate}
  \item \( row(A) = \text{span of the rows of } A \)
  \item \( col(A) = \text{span of the cols of } A \)
  \item \( null(A) = \{\vec{x}\in\R^n\mid A\vec{x} = \vec{0}\} \)
\end{enumerate}

\subsection*{Basis/Dimension for a Subspace}
A basis \( B = \{\vec{v_1},\dots,\vec{v_k}\} \) for \( S \) is a linearly
independent set such that \( span(B) = S \). The dimension \( S \) is the
number of elements of basis \( B \). If we have \( m \) vectors in a subspace
of dimension \( n \), where \( m > n \), then this set is linearly dependent.
The dimension \( dim(S) \) is the number of elements in a basis for \( S \).
Any \( \vec{x}\in S \) can be written uniquely as a linear combination of
elements of \( B \).

\subsection*{Fundamental Theorem of Invertible Matrices}
Let \( A \) be an \( n\times n \) matrix. The following are equivalent:
\begin{enumerate}
  \item \( A \) is invertible.
  \item \( A\vec{x} = \vec{b} \) has a unique solution \( \forall{b}\in\R^n \).
  \item \( A\vec{x} = \vec{0} \) has only the trivial solution.
  \item The reduced row echelon form of \( A \) is \( I_n \).
  \item \( A \) is the product of elementary matrices.
  \item \( rank(A) = n \)
  \item \( nullity(A) = 0 \)
  \item The column vectors of \( A \) are linearly independent.
  \item The column vectors of \( A \) span \( \R^n \).
  \item The column vectors of \( A \) form a basis for \( \R^n \).
  \item The row vectors of \( A \) are linearly independent.
  \item The row vectors of \( A \) span \( \R^n \).
  \item The row vectors of \( A \) form a basis of \( \R^n \).
\end{enumerate}
\textbf{Definition}: The rank of a matrix \( A \):
\[ rank(A) = dim(col~A) = dim(row~A) \]
\textbf{Definition}: \( nullity(A) = dim(null(A)) \) \\
\textbf{Definition}: Let \( A \) be \( m\times n \). then
\[ n = rank(A)+nullity(A) \]

\subsubsection*{Example}
\[ M = \begin{bmatrix}2 & 3 \\ 1 & 5 \\ 4 & 7 \\ 3 & 6\end{bmatrix} \]
\[ N = \begin{bmatrix}2 & 1 & -2 & -1 \\ 4 & 4 & -3 & 1 \\ 2 & 7 & 1 &
  8\end{bmatrix} \]
Find the rank and nullity of \( M \) and \( N \). \\ \\
For \( M \) the columns are clearly linearly independent, so \( rank(M) = 2 \),
and \( nullity(M) = 0 \). \\
For \( N \):
\[ N~\begin{bmatrix}2 & 1 & -2 & -1 \\ 0 & 2 & 1 & 3 \\ 0 & 0 & 0 &
  0\end{bmatrix} \]
Thus, \( rank(N) = 2 \) and \( nullity(N) = 2 \).

\begin{center}
  You can find all my notes at \url{http://omgimanerd.tech/notes}. If you have
  any questions, comments, or concerns, please contact me at
  alvin@omgimanerd.tech
\end{center}

\end{document}
