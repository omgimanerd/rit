\documentclass[letterpaper, 12pt]{math}

\usepackage{forest}

\title{Probability and Statistics}
\author{Alvin Lin}
\date{Probability and Statistics: January 2017 - May 2017}

\begin{document}

\maketitle

\section*{Probability}
The sample space of an experiment, denoted by \( S \), is the set of all
possible outcomes of the experiment. An event of the experiment is a subset
of \( S \). An event is simple if it consists of exactly one outcome, and
compound if it consists of more than one outcome. \par
Let \( A \) and \( B \) be events of an experiment. If \( A = \varnothing \),
then it is said to be the null event. \par
If \( A \cap B = \varnothing \), then \( A \) and \( B \) are said to be mutually
exclusive, or disjoint.

\subsection*{Roll a Die}
\[ S = \big\{ 1, 2, 3, 4, 5, 6 \big\} \]
Sample events:
\begin{itemize}
  \item \( E_{1}: \) getting a 1
  \item \( E_{2}: \) getting an even number
  \item \( E_{3}: \) getting a number greater than 4
  \item \( E_{4}: \) getting a number greater than 9
  \item \( E_{5}: \) getting an integer greater than 0 and less than 7
\end{itemize}
\begin{align*}
  E_{1} &= \big\{ 1 \big\} \subset S \\
  E_{2} &= \big\{ 2, 4, 6, \big\} \subset S \\
  E_{3} &= \big\{ 5, 6 \big\} \subset S \\
  E_{4} &= \big\{ \big\} = \varnothing \subset S \\
  E_{5} &= \big\{ 1, 2, 3, 4, 5, 6 \big\} \subset S
\end{align*}
\( E_{1} \) is a simple event. \( E_{2}, E_{3}, E_{5} \) are compound events.
\( E_{4} \) is the null event. \par
The events \( E_{1} \) and \( E_{2} \) are mutually exclusive or disjoint.
\[ E_{1} \cap E_{2} = \varnothing \]
The events \( E_{2} \) and \( E_{3} \) are not mutually exclusive or disjoint.
\[ E_{2} \cap E_{3} = \big\{ 6 \big\} \neq \varnothing \]

\subsection*{Example}
A family consisting of three persons - A, B, and C - goes to a medical clinic
that always has a doctor at stations 1, 2, and 3. During a certain week, each
member of the family visits the clinic once and is assigned at random to a
station. The experiment consists of recording the station number for each
member.
\renewcommand{\labelenumi}{\Alph{enumi}.}
\begin{enumerate}
  \item List 27 outcomes in the sample space. \\
    \begin{center}
      \begin{forest}
        [1
          [1 [1] [2] [3]]
          [2 [1] [2] [3]]
          [3 [1] [2] [3]]
        ]
      \end{forest}
      \newline
      \begin{forest}
        [2
          [1 [1] [2] [3]]
          [2 [1] [2] [3]]
          [3 [1] [2] [3]]
        ]
      \end{forest}
      \newline
      \begin{forest}
        [3
          [1 [1] [2] [3]]
          [2 [1] [2] [3]]
          [3 [1] [2] [3]]
        ]
      \end{forest}
    \end{center}
  \item List all outcomes in the event that all three members go to the same
    station.
    \[ 111, 222, 333 \]
  \item List all outcomes in the event that all members go to different
    stations.
    \[ 123, 132, 213, 231, 312, 321 \]
    There are \( 3! = 6 \) possibilities for these outcomes.
  \item List all outcomes in the event that no one goes to station 2.
    \[ 111, 113, 131, 133, 311, 313, 331, 333 \]
\end{enumerate}

\subsection*{Example}
Consider the experiment of tossing a coin which has U on one side and D on the
other side. \\
Sample space:
\[ S = \bigg\{ U, D \bigg\} \]
All possible events:
\[ \varnothing \quad \bigg\{ U \bigg\} \quad \bigg\{ D \bigg\} \quad
   \bigg\{ U, D \bigg\} \]
The probability of these events are:
\begin{align*}
  P(\{ \}) &= 0 \\
  P(\{ U \}) &= \frac{1}{2} \\
  P(\{ D \}) &= \frac{1}{2} \\
  P(\{ U, D \}) &= 1
\end{align*}
Let \( 2^{S} \) denote the power set of \( S \). Then:
\[ 2^{S} = \bigg\{ \varnothing, \{ U \}, \{ D \}, \{ U, D \} \bigg\} \]
P can be viewed as a function from \( 2^{S} \) to \( \R \).
\[ P:2^{S} \to \R \]
\[ \bigg\{ \varnothing \bigg\} \to 0 \]
\[ \bigg\{ \{ U \}, \{ D \} \bigg\} \to \frac{1}{2} \]
\[ \bigg\{ \{ U, D \} \bigg\} \to 1 \]
Let:
\[ \alpha = \bigg\{ (S, f:2^{S} \to \R) \mid \mathrm{S\ is\ a\ nonempty\
   countable\ set} \bigg\} \]
\[ \beta = \bigg\{(S, f:2^{S} \to \R) \in \alpha \mid (S, f)
   \mathrm{\ satisfies\ conditions\ 1,\ 2,\ and\ 3} \bigg\} \]
We can choose some conditions 1, 2, and 3 to research further about
\( \beta \).

\subsection*{Axioms}
\begin{enumerate}
  \item For any event \( A, P(A) \geq 0 \)
  \item \( P(S) = 1 \)
  \item If \( A_{1}, A_{2}, A_{3}, \dots \) is an infinite collection of
    disjoint events, the \( P(A_{1} \cup A_{2} \cup A_{3} \cup \dots) =
    \sum_{i=0}^{\infty}P(A_{i}) \).
\end{enumerate}
\( P(\varnothing) = 0 \) is proven from the axioms. The proof does not rely on
the following definition:
\[ P(E) = \frac{\mathrm{\#\ of\ outcomes\ favorable\ to\ E}}
   {\mathrm{total\ \#\ of\ possible\ outcomes}} \]

\subsection*{Example}
Toss a coin and select a ball from a basket containing 3 balls marked R, B, and
G.
\begin{align*}
  E_{1}&: getting\ a\ B \\
  E_{2}&: getting\ an\ H\ and\ then\ a\ B\ or\ G \\
  E_{3}&: not\ E_{2} \\
  E_{4}&: getting\ an\ H\ and\ then\ a\ B
\end{align*}
Consider the following probabilities:
\begin{align*}
  P(E_{1}) &= \frac{2}{6} \\
  P(E_{2}) &= \frac{2}{6} \\
  P(E_{3}) &= \frac{4}{6} \\
  P(E_{4}) &= \frac{1}{6}
\end{align*}
\( E_{4} \) is a simple event.
\begin{align*}
  P(E_{2}\ or\ E_{3}) &= P(E_{2}\ or\ not\ E_{2}) \\
  &= P(S) \\
  &= 1 \\
  &= P(E_{2} \cup E_{3}) &= \\
  P(E_{2}\ or\ E_{3}) &= P(E_{2}) + P(E_{3})
\end{align*}

\subsection*{Example}
A 5-sided rock has the following experimental result from tossing 1000 times.
\begin{center}
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Side      & 1   & 2   & 3   & 4   & 5 \\
    \hline
    Frequency & 320 & 180 & 150 & 130 & 220 \\
    \hline
  \end{tabular}
\end{center}
Our experiment: toss that rock and then toss a coin.
\begin{align*}
  E_{1}&: a\ 2\ and\ then\ an\ H \\
  E_{2}&: an\ odd\ number\ and\ then\ an\ H \\
  E_{3}&: an\ odd\ number\ or\ 2\ and\ then\ H
\end{align*}
Probabilities:
\begin{align*}
  P(E_{1}) &\neq \frac{1}{10} \\
  P(E_{1}) &= \frac{180}{1000}\frac{1}{2} \\
  P(E_{2}) &= \frac{320}{1000}\frac{1}{2} + \frac{150}{1000}\frac{1}{2}+
    \frac{220}{1000}\frac{1}{2} \\
  P(E_{3}) &= P(E_{2}) + \frac{180}{1000}\frac{1}{2}
\end{align*}

\subsection*{Example}
Roll a die twice. \\
E: the sum of the two numbers is at least 3
\begin{center}
  \begin{forest}
    [
      [1 [1 2 3 4 5 6]]
      [2 [1 2 3 4 5 6]]
      [3 [1 2 3 4 5 6]]
      [4 [1 2 3 4 5 6]]
      [5 [1 2 3 4 5 6]]
      [6 [1 2 3 4 5 6]]
    ]
  \end{forest}
\end{center}
\[ P(E) = \frac{\#\ of\ outcomes\ favorable\ to\ E}
   {total\ \#\ of\ possible\ outcomes} \]
We can sum up the number of rows where the sum is 3, 4, 5, etc, but since
the number of outcomes favorable to ``not E'' is a disjoint set, we can
sum up the number of rows where the sum is 2, 1, and 0. \\
Number of rows where the sum is 2: 1 \\
Number of rows where the sum is 1: 0 \\
Number of rows where the sum is 0: 0
\[ P(not\ E) = \frac{1}{36} \]
\[ P(E)+P(not\ E) = 1\]
\[ \therefore P(E) = 1-P(not\ E) = 1-\frac{1}{36} = \frac{35}{36} \]

\subsection*{Example}
The manager at Arango Automotive has found that the probability that a car
brought into the shop requires an oil change is 0.6, the probability that a car
requires brake repair is 0.2, and the probability that a car requires both an
oil change and brake repair is 0.1. For a car brought into the shop, determine
the probability that the car will require an oil change or brake repair.
\begin{align*}
  P(oil \cup brake) &= P(oil) + P(brake) - P(oil \cap brake) \\
  &= 0.6 + 0.2 - 0.1 \\
  &= 0.7
\end{align*}

General formula:
\[ P(A \cup B) = P(A)+P(B)-P(A \cap B) \]

\begin{center}
  You can find all my notes at \url{http://omgimanerd.tech/notes}. If you have
  any questions, comments, or concerns, please contact me at
  alvin@omgimanerd.tech
\end{center}

\end{document}
