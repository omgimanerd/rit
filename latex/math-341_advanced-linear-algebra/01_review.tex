\documentclass{math}

\usepackage{tikz}

\title{Advanced Linear Algebra}
\author{Alvin Lin}
\date{January 2019 - May 2019}

\begin{document}

\maketitle

\section*{Basic Review}
To define a plane, we need a point on the plane and a normal vector, or two
vectors on the plane.
\[ \vec{n}\cdot(\vec{x}-\vec{p}) = 0 \]
This is the point normal form of a plane (where \( \vec{n} \) is the normal
vector, \( \vec{p} \) is the point, and \( \vec{x} \) is a vector on the plane).
If instead we are given a point \( \vec{p} \) and two vectors \( \vec{u} \) and
\( \vec{v} \), we can describe any point in the plane as a linear combination of
\( \vec{u} \) and \( \vec{v} \).
\[ s\vec{u}+t\vec{v} = \vec{x}-\vec{p} \]
This is the vector form of a plane.

\subsubsection*{Example}
Find the equation of the plane that contains \( (6,0,1) \) and has normal vector
\( \vec{n} = \begin{bmatrix}1 \\ 2 \\ 3\end{bmatrix} \).
\begin{align*}
  \langle1,2,3\rangle\cdot(\langle x,y,z\rangle-\langle6,0,1\rangle) &= 0 \\
  \langle1,2,3\rangle\cdot\langle x-6,y-0,z-1\rangle &= 0 \\
  1(x-6)+2y+3(z-1) &= 0 \\
  x-6+2y+3z-3 &= 0 \\
  x+2y+3z &= 9
\end{align*}
Knowing \( \vec{p} = \langle6,0,1\rangle \) is on the plane, find the vector
form. To do this, we need to find two other points \( Q \) and \( R \) in the
plane. We can pick these arbitrarily by plugging them into the equation.
\begin{align*}
  Q &= (9,0,0) \\
  R &= (3,3,0)
\end{align*}
We can then construct the vectors \( \vec{u} \) and \( \vec{v} \) by calculating
the vector between Q and the point represented by \( \vec{p} \), and analogously
for point R.
\begin{align*}
  \vec{u} &= \overrightarrow{QP} = \langle9,0,0\rangle-\langle6,0,1\rangle =
    \langle3,0,-1\rangle \\
  \vec{v} &= \overrightarrow{RP} = \langle3,3,0\rangle-\langle6,0,1\rangle =
    \langle-3,3,-1\rangle
\end{align*}
These two vectors can then construct the vector form of the plane.
\begin{align*}
  \begin{bmatrix}x \\ y \\ z\end{bmatrix} &=
    \begin{bmatrix} 6 \\ 0 \\ 1\end{bmatrix}+
    s\begin{bmatrix}3 \\ 0 \\ -1\end{bmatrix}+
    t\begin{bmatrix}-3 \\ 3 \\ -1\end{bmatrix} \\
  x &= 6+3s-3t \\
  y &= 3t \\
  z &= 1-s-t
\end{align*}

\subsection*{Systems of Linear Equations}
For two lines in \( \R^2 \), two lines can either intersect at a single point,
infinitely many points if they lie on top of each other, or no points if they
are parallel.
\begin{align*}
  x-y &= 1 \\
  x+y &= 3
\end{align*}
\begin{center}
  \begin{tikzpicture}[scale=0.7]
    \draw[thick,<->] (-5,0) -- (5,0);
    \draw[thick,<->] (0,-5) -- (0,5);
    \draw[red] (-2,-3) -- (3,2);
    \draw[red] (-2,5) -- (3,0);
    \draw[fill=black] (2,1) circle (0.1cm);
  \end{tikzpicture}
\end{center}
These are two lines that intersect with a unique solution at \( (3,1) \). As
counterexamples:
\begin{align*}
  x-y &= 2 \\
  2x-2y &= 4
\end{align*}
These two lines lie on top of each other, resulting in infinitely many
solutions.
\begin{align*}
  x-y &= 1 \\
  x-y &= 3
\end{align*}
These two lines are parallel, and have no solutions.

\subsection*{Gaussian Elimination}
We can use Gaussian Elimination to solve systems of linear equations.
\begin{align*}
  x-y-z &= 2 \\
  3x-3y+2x &= 16 \\
  2x-y+z &= 9
\end{align*}
We can compose these equations into an augmented matrix.
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 \\
  3 & -3 & 2 & 16 \\
  2 & -1 & 1 & 9
\end{bmatrix} \]
The goal is acquire an upper triangular matrix. First perform \( R_2-3R_1 \)
and replace \( R_2 \) with the result.
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 \\
  0 & 0 & 5 & 10 \\
  2 & -1 & 1 & 9
\end{bmatrix} \]
Then we perform \( R_3-2R_1 \) and replace \( R_3 \) with the result.
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 \\
  0 & 0 & 5 & 10 \\
  0 & 1 & 3 & 5
\end{bmatrix} \]
We can now swap \( R_2 \) and \( R_3 \).
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 \\
  0 & 1 & 3 & 5 \\
  0 & 0 & 5 & 10
\end{bmatrix} \]
This matrix is now in row echelon form, where the leading entry in any row has
zeroes below it. From this point, we can perform back substitution to get back
a system of equations:
\begin{align*}
  5z &= 10 \quad z = 2 \\
  y+3z &= 5 \quad y+6 = 5 \quad y = -1 \\
  x-y-z &= 2 \quad x = 2+(-1)+(2) = 3 \\
  (x,y,z) &= (3,-1,2)
\end{align*}

\subsubsection*{Example}
Here is an example of a system of linear equations with 3 equations and 3
unknowns that has no solution.
\begin{align*}
  x_1-x_2+2x_3 &= 3 \\
  x_1+2x_2-x_3 &= -3 \\
  2x_2-2x_3 &= 1
\end{align*}
First we form it into an augmented matrix.
\[ \begin{bmatrix}
  1 & -1 & 2 & 3 \\
  1 & 2 & -1 & -3 \\
  0 & 2 & -2 & 1
\end{bmatrix} \]
For our first row reduction, we will pivot off the first row by subtracting it
from the second row.
\[ \begin{bmatrix}
  1 & -1 & 2 & 3 \\
  0 & 3 & -3 & -6 \\
  0 & 2 & -2 & 1
\end{bmatrix} \]
For simplicity, we will divide the second row by 3.
\[ \begin{bmatrix}
  1 & -1 & 2 & 3 \\
  0 & 1 & -1 & -2 \\
  0 & 2 & -2 & 1
\end{bmatrix} \]
Our goal is to obtain an upper triangular matrix, so we can try performing
\( R_3-2R_1 \) and placing it back in \( R_3 \).
\[ \begin{bmatrix}
  1 & -1 & 2 & 3 \\
  0 & 1 & -1 & -2 \\
  0 & 0 & 0 & 5
\end{bmatrix} \]
With the matrix in row-echelon form, we can conclude that there is no solution,
because our third row will translate to \( 0x_1+0x_2+0x_3 = 5 \). This system
of linear equations is inconsistent. \par
If we rewrite the system of linear equations as an equation with matrices, we
can reintroduce some ideas.
\begin{align*}
  A\vec{x} &= \vec{b} \\
  \begin{bmatrix}
    1 & -1 & 2 \\
    1 & 2 & -1 \\
    0 & 2 & -2
  \end{bmatrix}\begin{bmatrix}
    x_1 \\ x_2 \\ x_3
  \end{bmatrix} &= \begin{bmatrix}
    3 \\ -3 \\ 1
  \end{bmatrix} \\
  x_1\begin{bmatrix}1 \\ 1 \\ 0\end{bmatrix}+
    x_2\begin{bmatrix}-1 \\ 2 \\ 2\end{bmatrix}+
    x_3\begin{bmatrix}2 \\ -1 \\ -2\end{bmatrix} &=
  \begin{bmatrix}3 \\ -3 \\ 1\end{bmatrix}
\end{align*}
The right hand side of the equation cannot be expressed as a linear combination
of the columns of \( A \). In general, \(
span\{\vec{v_1},\vec{v_2},\dots,\vec{v_k} \) is the set of all linear
combinations \( c_1\vec{v_1}+c_2\vec{v_2}+\dots+c_k\vec{v_k} \). In this
example, the right hand side is not in the span of the column vectors.

\subsubsection*{Example}
Here is an example of 3 equations with 4 unknowns that have infinite solutions.
\begin{align*}
  w-x-y+2x &= 1 \\
  2x-2x-y+3z &= 3 \\
  -w+x-y &= -3
\end{align*}
Again, we form it into an augmented matrix.
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 & 1 \\
  2 & -2 & -1 & 3 & 3 \\
  -1 & 1 & -1 & 0 & -3
\end{bmatrix} \]
Pivoting off the first row, we will perform \( R_2-2R_1 \) and replace \( R_2 \)
with the result. We will then perform \( R_3+R_1 \) and replace \( R_3 \) with
the result.
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 & 1 \\
  0 & 0 & 1 & -1 & 1 \\
  0 & 0 & -2 & 2 & -2
\end{bmatrix} \]
We can now attempt to pivot off the second row and perform \( R_3+2R_2 \),
replacing \( R_3 \) with the result.
\[ \begin{bmatrix}
  1 & -1 & -1 & 2 & 1 \\
  0 & 0 & 1 & -1 & 1 \\
  0 & 0 & 0 & 0 & 0
\end{bmatrix} \]
This matrix is now in row-echelon form. We can go one step further and put it
into reduced row-echelon form. We can do this by performing \( R_1+R_2 \) and
replacing \( R_1 \) with the result.
\[ \begin{bmatrix}
  1 & -1 & 0 & 1 & 2 \\
  0 & 0 & 1 & -1 & 1 \\
  0 & 0 & 0 & 0 & 0
\end{bmatrix} \]
In terms of equations, this matrix tells us the following:
\begin{align*}
  w-x+z &= 2 \\
  y-z &= 1
\end{align*}
Two equations is only enough to constrain two variables, which means we have two
unconstrained variables. If we arbitrarily pick \( w \) and \( y \) as our
constrained variables, we can rewrite our equations in terms of our free
variables.
\begin{align*}
  x &= s \quad z = t \\
  \begin{bmatrix}w \\ x \\ y \\ z\end{bmatrix} &=
    \begin{bmatrix}
      2+s-t \\
      s \\
      1+t \\
      t
    \end{bmatrix} \quad -\infty<s,t<\infty \\
\end{align*}
Going further, we can rewrite our solution space into a parameterized matrix
equation.
\[ \begin{bmatrix}w \\ x \\ y \\ z\end{bmatrix} =
  \begin{bmatrix}2 \\ 0 \\ 1 \\ 0\end{bmatrix}+
  s\begin{bmatrix}1 \\ 1 \\ 0 \\ 0\end{bmatrix}+
  t\begin{bmatrix}-1 \\ 0 \\ 1 \\ 1\end{bmatrix} \]
We can see from this parameterization that our solution space is a two parameter
infinite set spanned by two vectors in \( \R^4 \). Our coefficient matrix
\( A \) was a \( 3\times4 \) matrix. We can compute the rank of \( A \) by
counting the number of nonzero rows in its reduced row-echelon form, which is
2. The rank is analogous to the number of constrained equations that we have,
which is also equal to the number of constrained variables. \par

\subsubsection*{Rank-Nullity Theorem}
If \( n \) is the number of variables in the system (also the number of columns
in \( A \)), it is equal to the sum of the rank of \( A \) (constrained
variables) and the number of free variables. The number of free variables is
also known as the nullity of \( A \).

\subsubsection*{Null Space}
The null space of \( A \) is the subspace of \( \R^n \) consisting of solutions
to \( A\vec{x} = \vec{0} \) and is denoted by \( null(A) \). To compute the
null space of the above problem, we can replace \( \vec{b} \) with \( \vec{0} \)
and compute the reduced row-echelon form. This comes out to be
\[ \begin{bmatrix}
  1 & -1 & 0 & 1 & 0 \\
  0 & 0 & 1 & -1 & 0 \\
  0 & 0 & 0 & 0 & 0
\end{bmatrix} \]
We can rewrite this into a parameterized matrix equation.
\[ \begin{bmatrix}w \\ x \\ y \\ z\end{bmatrix} =
  s\begin{bmatrix}1 \\ 1 \\ 0 \\ 0\end{bmatrix}+
  t\begin{bmatrix}-1 \\ 0 \\ 1 \\ 1\end{bmatrix} \]
This comes out to the same form as our solution space. Our null space is just
the span of the two vectors in \( \R^4 \).

\subsection*{Subspaces}
Suppose we have the following:
\[ A\vec{x} = \vec{b} \]
We can represent the following in matrix form as:
\begin{align*}
  \begin{bmatrix}
    \vec{a_1} & \vec{a_2} & \dots & \vec{a_n}
  \end{bmatrix}\begin{bmatrix}
    x_1 \\ x_2 \\ \vdots x_n
  \end{bmatrix} &= \begin{bmatrix}
    b_1 \\ b_2 \\ \vdots b_n
  \end{bmatrix} \\
  x_1\vec{a_1}+x_2\vec{a_2}+\dots+x_n\vec{a_n} &= \vec{b}
\end{align*}
The span of the columns of \( A \) (all linear combinations of the columns)
is known as the column space of \( A \), while the span of the rows of \( A \)
(all linear combinations of the rows) is known as the row space. The system is
consistent if \( \vec{b} \) is in the column space of \( A \).

\subsubsection*{Example}
Find the row space, column space, and null space of \( A \).
\[ A = \begin{bmatrix}
  1 & 1 & 3 & 1 & 6 \\
  2 & -1 & 0 & 1 & -1 \\
  -3 & 2 & 1 & -2 & 1 \\
  4 & 1 & 6 & 1 & 3
\end{bmatrix} \]
The first step is to put the matrix into reduced row echelon form. For
simplicity, we will skip the row operation steps.
\begin{align*}
  rref(A) &= \begin{bmatrix}
    1 & 0 & 1 & 0 & -1 \\
    0 & 1 & 2 & 0 & 3 \\
    0 & 0 & 0 & 1 & 4 \\
    0 & 0 & 0 & 0 & 0
  \end{bmatrix} \\
  row(A) &= span\left\{
    \begin{bmatrix}1 \\ 0 \\ 1 \\ 0 \\ -1\end{bmatrix},
    \begin{bmatrix}0 \\ 1 \\ 2 \\ 0 \\ 3\end{bmatrix},
    \begin{bmatrix}0 \\ 0 \\ 0 \\ 1 \\ 4\end{bmatrix}
  \right\} \\
  col(A) &= span\left\{
    \begin{bmatrix}1 \\ 2 \\ -3 \\ 4\end{bmatrix},
    \begin{bmatrix}1 \\ -1 \\ 2 \\ 1\end{bmatrix},
    \begin{bmatrix}1 \\ 1 \\ -2 \\ 1\end{bmatrix}
  \right\}
\end{align*}
The row space of \( A \) is determined by the span of the nonzero rows. The
column space of \( A \) is determined by the span of the original columns which
correspond to columns with leading ones in reduced row echelon form. This
involves the first, second, and fourth columns. We can justify this by showing
that the third and fifth columns are linear combinations of the others. We need
the null space of \( A \) in order to determine this.
\begin{align*}
  null(A) &: A\vec{x} = \vec{0} \\
  &: x_1\vec{a_1}+x_2\vec{a_2}+\dots+x_n\vec{a_n} = \vec{0} \\
\end{align*}
We can compute the reduced row echelon form of the augmented matrix (taking
\( \vec{b} = \vec{0} \)).
\[ \begin{bmatrix}
  1 & 1 & 3 & 1 & 6 & 0 \\
  2 & -1 & 0 & 1 & -1 & 0 \\
  -3 & 2 & 1 & -2 & 1 & 0 \\
  4 & 1 & 6 & 1 & 3 & 0
\end{bmatrix} \to \begin{bmatrix}
  1 & 0 & 1 & 0 & -1 & 0 \\
  0 & 1 & 2 & 0 & 3 & 0 \\
  0 & 0 & 0 & 1 & 4 & 0 \\
  0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix} \]
We can rewrite our null space as a system of equations.
\begin{align*}
  x_1+x_3-x_5 &= 0 \\
  x_2+2x_3+3x_5 &= 0 \\
  x_4+4x_5 &= 0
\end{align*}
If we let \( x_3 = s, x_5 = t \), we can write our null space as a span of
two vectors.
\begin{align*}
  \begin{bmatrix}x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5\end{bmatrix} &=
    s\begin{bmatrix}-1 \\ -2 \\ 1 \\ 0 \\ 0\end{bmatrix}+
    t\begin{bmatrix}1 \\ -3 \\ 0 \\ -4 \\ 1\end{bmatrix},
      \quad \infty<s,t<\infty \\
  null(A) &= span\left\{
    \begin{bmatrix}-1 \\ -2 \\ 1 \\ 0 \\ 0\end{bmatrix},
    \begin{bmatrix}1 \\ -3 \\ 0 \\ -4 \\ 1\end{bmatrix}
  \right\}
\end{align*}
The entries in the null space represent the column dependencies of \( A \) and
the reduced row echelon form of \( A \).
\[ A\vec{x} = \vec{0} \quad\forall\quad \vec{x}\in null(A) \]
The entries in the null space describe how we can represent the third and fifth
column as linear combinations of the others.
\begin{align*}
  \begin{bmatrix}-1 \\ -2 \\ 1 \\ 0 \\ 0\end{bmatrix} &\to
    -\vec{x_1}-2\vec{x_2}+\vec{x_3} = \vec{0} \\
  & -\vec{x_1}-2\vec{x_1} = \vec{x_3} \\
  \begin{bmatrix}1 \\ -3 \\ 0 \\ -4 \\ 1\end{bmatrix} &\to
    \vec{x_1}-3\vec{x_2}-4\vec{x_4}+\vec{x_5} = \vec{0} \\
  & \vec{x_1}-3\vec{x_2}-4\vec{x_4} = -\vec{x_5}
\end{align*}
The dimensionality of the null space is known as the nullity of \( A \). In this
case, \( dim(null(A)) = 2 \). Another surprising fact is that the the row space
is orthogonal to the null space.
\begin{align*}
  \begin{bmatrix}\vec{r_1} \\ \vec{r_2} \\ \vdots \\ \vec{r_m}\end{bmatrix}
    \begin{bmatrix}x_1 \\ x_2 \\ \vdots \\ x_n\end{bmatrix} &=
    \begin{bmatrix}0 \\ 0 \\ \vdots \\ 0\end{bmatrix} \\
  \begin{bmatrix}
    \vec{r_1}\cdot\vec{x} \\
    \vec{r_2}\cdot\vec{x} \\
    \vdots \\
    \vec{r_m}\cdot\vec{x}
  \end{bmatrix} &= \begin{bmatrix}0 \\ 0 \\ \vdots \\ 0\end{bmatrix}
\end{align*}
If \( \vec{x} \) is in the null space, then it must be perpendicular to the
rows, and therefore it must be perpendicular to the row space of \( A \).
\begin{align*}
  row(A) &= span\left\{\vec{r_1},\vec{r_2},\dots,\vec{r_n}\right\} \\
  null(A) &= \left\{\vec{x}\mid A\vec{x} = \vec{0}\right\} \\
  row(A) &\bot null(A)
\end{align*}

\subsection*{Inverses}
To compute the inverse of a matrix, the most elementary way to do it is to
augment the matrix with the identity matrix and perform row operations until
you have the identity matrix on the left. For example:
\[ \begin{bmatrix}
  1 & 2 & -1 & 1 & 0 & 0 \\
  2 & 2 & 4 & 0 & 1 & 0 \\
  1 & 3 & -3 & 0 & 0 & 1
\end{bmatrix} \]
After applying the necessary row operations, we are left with:
\[ \begin{bmatrix}
  1 & 0 & 0 & 9 & -\frac{3}{2} & -5 \\
  0 & 1 & 0 & -5 & 1 & 3 \\
  0 & 0 & 1 & -2 & \frac{1}{2} & 1
\end{bmatrix} \]
If \( A \) is an \( n\times n \) matrix, then the following statements are
equivalent.
\begin{itemize}
  \item A is invertible.
  \item The determinant of A is not equal to 0.
  \item \( A\vec{x} = \vec{b} \) has a unique solution for every \( \vec{b} \).
  \item \( A\vec{x} = \vec{0} \) has only the trivial solution.
  \item The reduced row echelon form of \( A \) is the identity matrix.
  \item \( rank(A) = n \)
  \item \( nullity(A) = 0 \)
  \item The row vectors of \( A \) form a basis for \( \R^n \).
  \item The columns vectors of \( A \) form a basis for \( \R^n \).
\end{itemize}

\subsection*{Determinant}
Computing the determinant of a \( 2x2 \) matrix is trivial.
\begin{align*}
  A &= \begin{bmatrix}
    a_{11} & a_{12} \\
    a_{21} & a_{22}
  \end{bmatrix} \\
  \det(A) &= |A| = \begin{vmatrix}
    a_{11} & a_{12} \\
    a_{21} & a_{22}
  \end{vmatrix} \\
  &= a_{11}a_{22}-a_{12}a_{21}
\end{align*}
Computing the determinant of an \( n\times n \) matrix requires cofactor
expansion along the first row (although it can be done).
\begin{align*}
  \det(A) &=
    a_{11}\det(A_{11})-a_{12}\det(A_{12})+\dots+(-1)^{1+n}a_{1n}\det(A_{1n}) \\
  &= \sum_{j=1}^{n}(-1)^{i+j}a_{ij}\det(A_{ij}) \\
  &= \sum_{j=1}^{n}a_{ij}C_{ij} \\
  C_{ij} &= (-1)^{i+j}\det(A_{ij})
\end{align*}
If \( A \) is an \( n\times n \) square matrix, it has the following properties:
\begin{itemize}
  \item If \( A \) has a row of zeros, then the determinant of \( A \) is 0.
  \item If \( B \) is obtained by interchanging two rows of \( A \), then
    \( \det(B) = -\det(A) \).
  \item If \( A \) has two identical rows, then the determinant of \( A \) is 0.
  \item If \( B \) is obtained by multiplying a row of \( A \) by some constant
    \( k \), then \( \det(B) = k\det(B) \).
  \item If \( B \) is obtained by adding a multiple of one row of \( A \) to
    another row, then \( \det(B) = \det(A) \).
  \item \( \det(kA) = k^n\det(A) \)
  \item \( \det(AB) = (\det(A))(\det(B)) \)
  \item \( \det(A^{-1}) = \frac{1}{\det(A)} \)
  \item \( \det(A^T) = \det(A) \)
\end{itemize}

\subsubsection*{Example}
\begin{align*}
  A &= \begin{bmatrix}
    5 & -3 & 2 \\
    1 & 0 & 2 \\
    2 & -1 & 3
  \end{bmatrix} \\
  \det(A) &= 5\begin{vmatrix}
    0 & 2 \\
    -1 & 3
  \end{vmatrix}-(-3)\begin{vmatrix}
    1 & 2 \\
    2 & 3
  \end{vmatrix}+2\begin{vmatrix}
    1 & 0 \\
    2 & -1
  \end{vmatrix} \\
  &= 5(0+2)+3(3-4)+2(-1-0) \\
  &= 10-3-2 = 5
\end{align*}

\begin{center}
  You can find all my notes at \url{http://omgimanerd.tech/notes}. If you have
  any questions, comments, or concerns, please contact me at
  alvin@omgimanerd.tech
\end{center}

\end{document}
