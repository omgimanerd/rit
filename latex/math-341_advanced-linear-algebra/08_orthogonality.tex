\documentclass{math}

\title{Advanced Linear Algebra}
\author{Alvin Lin}
\date{January 2019 - May 2019}

\begin{document}

\maketitle

\section*{Orthogonality}
Recall that the orthogonal projection of \( \vec{v} \) onto \( \hat{u} \) is
defined as:
\begin{align*}
  \vec{v}\cdot\hat{u} &= \|\vec{v}\|\|\hat{u}\|\cos\theta \\
  \text{proj}_{\hat{u}}\vec{v} &= (\|\vec{v}\|\cos\theta)\hat{u} \\
  &= \|\vec{v}\|\frac{\vec{v}\cdot\hat{u}}{\|\vec{v}\|}\hat{u} \\
  &= (\langle v_1,v_2\rangle\cdot\langle u_1,u_2\rangle)\begin{bmatrix}
    u_1 \\ u_2
  \end{bmatrix} \\
  &= (v_1u_1+v_2u_2)\begin{bmatrix}
    u_1 \\ u_2
  \end{bmatrix} \\
  &= \begin{bmatrix}
    v_1u_1^2+v_2u_1u_2 \\
    v_1u_1u_2+v_2u_2^2
  \end{bmatrix} \\
  &= \begin{bmatrix}
    u_1^2 & u_1u_2 \\
    u_1u_2 & u_2^2
  \end{bmatrix}\begin{bmatrix}
    v_1 \\ v_2
  \end{bmatrix} \\
  &= P\vec{v}
\end{align*}
If we look at the projection matrix, we observe the following:
\begin{align*}
  P &= \begin{bmatrix}
    u_1^2 & u_1u_2 \\
    u_1u_2 & u_2^2
  \end{bmatrix} \\
  &= \begin{bmatrix}u_1 \\ u_2\end{bmatrix}
    \begin{bmatrix}u_1 & u_2\end{bmatrix} \\
  &= \hat{u}\hat{u}^T
\end{align*}
Projection is a linear transformation that can be expressed as a matrix
operation.

\subsubsection*{Example}
Given \( \hat{u} = \begin{bmatrix}\frac{1}{\sqrt{2}} \\
-\frac{1}{\sqrt{2}}\end{bmatrix} \) and \( \vec{v} = \begin{bmatrix}3 \\
4\end{bmatrix} \), find \( \text{proj}_{\hat{u}}\vec{v} \).
\begin{align*}
  P &= \hat{u}\hat{u}^T \\
  &= \begin{bmatrix}
    \frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}}
  \end{bmatrix}\begin{bmatrix}
    \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}}
  \end{bmatrix} \\
  &= \begin{bmatrix}
    \frac{1}{2} & -\frac{1}{2} \\
    -\frac{1}{2} & \frac{1}{2}
  \end{bmatrix} \\
  \text{proj}_{\hat{u}}\vec{v} &= \begin{bmatrix}
    \frac{1}{2} & -\frac{1}{2} \\
    -\frac{1}{2} & \frac{1}{2}
  \end{bmatrix}\begin{bmatrix}
    3 \\ -4
  \end{bmatrix} \\
  &= \begin{bmatrix}
    \frac{7}{2} \\ -\frac{7}{2}
  \end{bmatrix}
\end{align*}

\subsubsection*{Example}
Show that \( P = \hat{u}\hat{u}^T \) is symmetric.
\begin{align*}
  P^T &= (\hat{u}\hat{u}^T)^T \\
  &= (\hat{u}^T)^T(\hat{u})^T \\
  &= \hat{u}\hat{u}^T
\end{align*}
Show that \( P^2 = P \) (P is idempotent).
\begin{align*}
  P^2 &= (\hat{u}\hat{u}^T)(\hat{u}\hat{u}^T) \\
  &= \hat{u}(\hat{u}^T\hat{u})\hat{u}^T \\
  \hat{u}^T\hat{u} &= 1 \\
  &= \hat{u}\hat{u}^T
\end{align*}

\subsection*{Orthogonal Projection of \( \vec{v} \) onto a Plane through Origin}
Given a plane, its normal vector \( \vec{n} \), a vector \( \vec{v} \), the
distance from the tip of \( \vec{v} \) to the plane is some length that can be
represented by a vector \( -c\vec{n} \). We can represent the projection of
\( \vec{v} \) onto the plane as \( \vec{p} = \vec{v}-c\vec{n} \).
\begin{align*}
  \vec{p} &= \vec{v}-c\vec{n} \\
  \vec{n}\cdot\vec{p} &= \vec{n}\cdot(\vec{v}-c\vec{n}) \\
  0 &= \vec{n}\cdot\vec{v}-c(\vec{n}\cdot\vec{n}) \\
  c &= \frac{\vec{n}\cdot\vec{v}}{\vec{n}\cdot\vec{n}}
\end{align*}
Alternatively, if instead of being given a unit vector \( \vec{n} \), suppose we
are given two orthogonal vectors \( \hat{u_1} \) and \( \hat{u_2} \) that span
the plane. Let \( \vec{p_1} = \text{proj}_{\hat{u_1}}\vec{v} \) and
\( \vec{p_2} = \text{proj}_{\hat{u_2}}\vec{v} \). The projection of
\( \vec{v} \) onto the plane spanned by \( \hat{u_1} \) and \( \hat{u_2} \) is
equal to \( \vec{p} = \vec{p_1}+\vec{p_2} \).
\begin{align*}
  \vec{p_1} &= \text{proj}_{\hat{u_1}}\vec{v} = \hat{u_1}\hat{u_1}^T\vec{v} \\
  \vec{p_2} &= \text{proj}_{\hat{u_2}}\vec{v} = \hat{u_2}\hat{u_2}^T\vec{v} \\
  \vec{p} &= \vec{p_1}+\vec{p_2} \\
  &= (\hat{u_1}\hat{u_1}^T+\hat{u_2}\hat{u_2}^T)\vec{v} = P\vec{v}
\end{align*}

\subsubsection*{Example}
Project \( \vec{v} = \langle1,0,-2\rangle \) onto the plane \( x+y+z = 0 \).
\begin{align*}
  \langle1,1,1\rangle\cdot\langle x,y,z\rangle &= 0 \\
  \vec{n} &= \langle1,1,1\rangle \\
  c &= \frac{\vec{n}\cdot\vec{v}}{\vec{n}\cdot\vec{n}} \\
  &= \frac{1+0-2}{1+1+1} \\
  &= -\frac{1}{2} \\
  \vec{p} &= \vec{v}+\frac{1}{3}\vec{n} \\
  &= \langle\frac{2}{3},-\frac{1}{3},-\frac{7}{3}\rangle
\end{align*}

\subsubsection*{Example}
Project \( \vec{v} = \langle1,0,-2\rangle \) onto \( x+y+z = 0 \) with
\( \hat{u_1} = \frac{1}{\sqrt{6}}\begin{bmatrix}-2 \\ 1 \\ 1\end{bmatrix} \)
and
\( \hat{u_2} = \frac{1}{\sqrt{2}}\begin{bmatrix}0 \\ 1 \\ -1\end{bmatrix} \).
\begin{align*}
  P &= \begin{bmatrix}
    -\frac{2}{\sqrt{6}} \\ \frac{1}{\sqrt{6}} \\ \frac{1}{\sqrt{6}}
  \end{bmatrix}\begin{bmatrix}
    -\frac{2}{\sqrt{6}} & \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{6}}
  \end{bmatrix}+\begin{bmatrix}
    0 \\ \frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}}
  \end{bmatrix}\begin{bmatrix}
    0 & \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
  \end{bmatrix} \\
  &= \begin{bmatrix}
    \frac{4}{6} & -\frac{2}{6} & -\frac{2}{6} \\
    -\frac{2}{6} & \frac{1}{6} & \frac{1}{6} \\
    -\frac{2}{6} & \frac{1}{6} & \frac{1}{6}
  \end{bmatrix}+\begin{bmatrix}
    0 & 0 & 0 \\
    0 & \frac{1}{2} & -\frac{1}{2} \\
    0 & -\frac{1}{2} & \frac{1}{2}
  \end{bmatrix} \\
  &= \frac{1}{6}\begin{bmatrix}
    4 & -2 & -2 \\
    -2 & 4 & -2 \\
    -2 & -2 & 4
  \end{bmatrix} \\
  P\vec{v} &= \frac{1}{6}\begin{bmatrix}
    4 & -2 & -2 \\
    -2 & 4 & -2 \\
    -2 & -2 & 4
  \end{bmatrix}\begin{bmatrix}1 \\ 0 \\ -2\end{bmatrix} \\
  &= \begin{bmatrix}
    \frac{8}{6} \\ \frac{2}{6} \\ -\frac{10}{6}
  \end{bmatrix} \\
  &= \begin{bmatrix}
    \frac{4}{3} \\ \frac{1}{3} \\ -\frac{5}{3}
  \end{bmatrix}
\end{align*}

\subsubsection*{Concept}
What is the rank of \( P = \hat{u_1}\hat{u_1}^T+\hat{u_2}\hat{u_2}^T \)? \par
Every vector in \( \R^3 \) gets mapped by \( P\vec{v} \) onto a two dimensional
plane, so that means that the column space of P must be two dimensional.

\subsection*{Orthogonality in \( \R^n \)}
A set of vectors is \textbf{orthogonal} if \( \vec{v_i}\cdot\vec{v_j} = 0,
i\ne j \). For example:
\[ \vec{v_1} = \begin{bmatrix}2 \\ 1 \\ -1\end{bmatrix} \quad
  \vec{v_2} = \begin{bmatrix}0 \\ 1 \\ 1\end{bmatrix} \quad
  \vec{v_3} = \begin{bmatrix}1 \\ -1 \\ 1\end{bmatrix} \]
An \textbf{orthogonal basis} is a basis that is an orthogonal set.

\subsubsection*{Example}
Find an orthogonal basis for the subspace \( W \) of \( \R^3 \) given by
\[ W = \left\{\begin{bmatrix}x \\ y \\ z\end{bmatrix}: x-y+2z = 0\right\} \]
\begin{align*}
  \begin{bmatrix}
    y-2z \\ y \\ z
  \end{bmatrix} &= y\begin{bmatrix}
    1 \\ 1 \\ 0
  \end{bmatrix}+z\begin{bmatrix}
    -2 \\ 0 \\ 1
  \end{bmatrix} \\
  \vec{u} &= \begin{bmatrix}1 \\ 1 \\ 0\end{bmatrix} \\
  \vec{v} &= \begin{bmatrix}-2 \\ 0 \\ 1\end{bmatrix}
\end{align*}
These two vectors form a basis for \( W \) but are not orthogonal. Let
\( \vec{w} = \begin{bmatrix}x \\ y \\z\end{bmatrix} \) be orthogonal to
\( \vec{u} \) in the plane.
\begin{align*}
  x-y+2z &= 0 \\
  \vec{w}\cdot\vec{u} &= 0 \\
  x+y &= 0 \quad y = -x \\
  2x+2z &= 0 \\
  \vec{w} &= \begin{bmatrix}-z \\ z \\ z\end{bmatrix} = z\begin{bmatrix}
    -1 \\ 1 \\ 1
  \end{bmatrix}
\end{align*}
This vector \( \vec{w} \) satisfies the equation and the orthogonality
condition.
\[ \vec{w} = \begin{bmatrix}-1 \\ 1 \\ 1\end{bmatrix} \quad
  \vec{u} = \begin{bmatrix}1 \\ 1 \\ 0\end{bmatrix} \]

\subsubsection*{Fact}
Let \( [\vec{v_1},\vec{v_2},\dots,\vec{v_k}] \) be an orthogonal basis for a
subspace \( W \). Let \( \vec{w} \) be any vector in \( W \).
\begin{align*}
  \vec{w} &= c_1\vec{v_1}+c_2\vec{v_2}+\dots+c_k\vec{v_k} \\
  c_1 &= \frac{\vec{v_1}\cdot\vec{w}}{\vec{v_1}\cdot\vec{v_1}} \\
  c_2 &= \frac{\vec{v_2}\cdot\vec{w}}{\vec{v_2}\cdot\vec{v_2}} \\
  &\dots \\
  c_i &= \frac{\vec{v_i}\cdot\vec{w}}{\vec{v_i}\cdot\vec{v_i}}
\end{align*}

\subsubsection*{Example}
Let \( \vec{w} = \begin{bmatrix}1 \\ 2 \\ 3\end{bmatrix} \). Find the
coordinates of \( \vec{w} \) with respect to
\[ \vec{v_1} = \begin{bmatrix}2 \\ 1 \\ -1\end{bmatrix}\quad
  \vec{v_2} = \begin{bmatrix}0 \\ 1 \\ 1\end{bmatrix}\quad
  \vec{v_3} = \begin{bmatrix}1 \\ -1 \\ 1\end{bmatrix} \]
\begin{align*}
  \vec{w} &= c_1\vec{v_1}+c_2\vec{v_2}+c_3\vec{v_3} \\
  c_1 &= \frac{2+2-3}{4+1+1} = \frac{1}{6} \\
  c_2 &= \frac{0+2+3}{0+1+1} = \frac{5}{2} \\
  c_3 &= \frac{1-2+3}{1+1+1} = \frac{2}{3}
\end{align*}

\subsection*{Orthonormality}
A set of vectors is \textbf{orthonormal} if it is an orthogonal set of unit
vectors. An orthonormal basis is a basis that is an orthonormal set. Let
\( [\hat{q_1},\hat{q_2},\dots,\hat{q_k}] \) be an orthonormal basis for a
subspace \( W \). Then \( \vec{w} = c_1\hat{q_1}+c_2\hat{q_2}+\dots+
c_k\hat{q_k} \) where \( c_i = \hat{q_i}\cdot\vec{w} \).

\subsection*{Orthogonal Matrices}
The columns of an \( m\times n \) matrix \( Q \) for an orthonormal set if
\( Q^TQ = I_n \).
\[ \begin{bmatrix}\hat{q_1} \\ \hat{q_2} \\ \vdots \\ \hat{q_n}\end{bmatrix}
  \begin{bmatrix}\hat{q_1} & \hat{q_2} & \dots & \hat{q_3}\end{bmatrix} =
  \begin{bmatrix}
    1 & 0 & \dots & 0 \\
    0 & 1 & \dots & 0 \\
    \vdots & \vdots & \vdots & \vdots \\
    0 & 0 & \dots & 1
  \end{bmatrix} \]
\textbf{Theorem:} An \( n\times n \) matrix \( Q \) whose columns form an
orthonormal set is called an ``orthogonal matrix''. A square matrix \( Q \) is
orthogonal if and only if \( Q^{-1} = Q^T \). Example:
\begin{align*}
  A &= \begin{bmatrix}
    0 & 1 & 0 \\
    0 & 0 & 1 \\
    1 & 0 & 0
  \end{bmatrix} \\
  A^T &= \begin{bmatrix}
    0 & 0 & 1 \\
    1 & 0 & 0 \\
    0 & 1 & 0
  \end{bmatrix} = A^{-1}
\end{align*}
Another example:
\begin{align*}
  B &= \begin{bmatrix}
    \cos\theta & -\sin\theta \\
    \sin\theta & \cos\theta
  \end{bmatrix} \\
  B^T &= \begin{bmatrix}
    \cos\theta & \sin\theta \\
    -\sin\theta & \cos\theta
  \end{bmatrix} = B^{-1}
\end{align*}
The following statements are equivalent:
\begin{enumerate}
  \item \( Q \) is orthogonal.
  \item \( \|Q\vec{x}\| = \|\vec{x}\| \) for every \( \vec{x} \) in \( \R^n \).
  \item \( (Q\vec{x})\cdot(Q\vec{y}) = \vec{x}\cdot\vec{y} \).
  \begin{align*}
    (Q\vec{x})\cdot(Q\vec{y}) &= (Q\vec{x})^T(Q\vec{y}) \\
    &= \vec{x}^TQ^TQ\vec{y} \\
    &= \vec{x}^T\vec{y} \\
    &= \vec{x}\cdot\vec{y}
  \end{align*}
\end{enumerate}
If \( Q \) is an orthogonal matrix \( (Q^{-1} = Q^T) \), the following
consequences result:
\begin{enumerate}
  \item \( Q^{-1} \) is orthogonal.
  \begin{align*}
    (Q^{-1})^{-1} &= (Q^{-1})^T \\
    Q &= (Q^T)^T \\
    Q &= Q
  \end{align*}
  \item \( \det(Q) = \pm1 \)
  \item If \( \lambda \) is an eigenvalue of \( Q \), then \( |\lambda| = 1 \).
  \begin{align*}
    Q\vec{v} &= \lambda\vec{v} \\
    \|Q\vec{v}\| &= \|\lambda\vec{v}\| \\
    \|\vec{v}\| &= |\lambda|\|\vec{v}\| \\
    1 &= \lambda
  \end{align*}
  \item If \( Q_1 \) and \( Q_2 \) are orthogonal then so is \( Q_1Q_2 \).
\end{enumerate}
\textbf{Theorem:} Let \( W \) be a subspace of \( \R^n \). The set of all
vectors that are orthogonal to \( W \) is called the ``orthogonal complement''.
\[ W^{\bot} = \{\vec{v}\in\R^n:\vec{v}\cdot\vec{w} = 0 \forall\vec{w}\in W\} \]
\textbf{Theorem:} Let \( A \) be an \( n\times n \) matrix. Then the orthogonal
complement of the row space is the null space.
\[ (row(A))^T = null(A) \]
\( \vec{x} \) is in the null space of \( A \) if \( \vec{a_i}\cdot\vec{x} = 0 \)
therefore every vector in the row space is orthogonal to every vector in the
null space. Also, note that \( (col(A))^{\bot} = null(A^T) \).

\subsubsection*{Example}
Let \( W \) be the subspace of \( \R^5 \) spanned by
\[ \vec{w_1} = \begin{bmatrix}1 \\ -3 \\ 5 \\ 0 \\ 5\end{bmatrix}\quad
  \vec{w_2} = \begin{bmatrix}-1 \\ 1 \\ 2 \\ -2 \\ 3\end{bmatrix}\quad
  \vec{w_3} = \begin{bmatrix}0 \\ -1 \\ 4 \\ -1 \\ 5\end{bmatrix} \]
Find a basis for \( W^{\bot} \).
\begin{align*}
  \begin{bmatrix}
    1 & -3 & 5 & 0 & 5 \\
    -1 & 1 & 2 & -2 & 3 \\
    0 & -1 & 4 & -1 & 5
  \end{bmatrix}\begin{bmatrix}
    x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
  \end{bmatrix} &= \begin{bmatrix}0 \\ 0 \\ 0\end{bmatrix} \\
  \begin{bmatrix}
    1 & -3 & 5 & 0 & 5 & 0 \\
    -1 & 1 & 2 & -2 & 3 & 0 \\
    0 & -1 & 4 & -1 & 5 & 0
  \end{bmatrix} &\to \begin{bmatrix}
    1 & 0 & 0 & 3 & 4 & 0 \\
    0 & 1 & 0 & 1 & 3 & 0 \\
    0 & 0 & 1 & 0 & 2 & 0
  \end{bmatrix} \\
  \begin{bmatrix}
    x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
  \end{bmatrix} &= \begin{bmatrix}
    -3x_4-4x_5 \\ -x_4-3x_5 \\ -2x_5 \\ x_4 \\ x_5
  \end{bmatrix} = x_4\begin{bmatrix}
    -3 \\ -1 \\ 0 \\ 1 \\ 0
  \end{bmatrix}+x_5\begin{bmatrix}
    -4 \\ -3 \\ -2 \\ 0 \\ 1
  \end{bmatrix} \\
  W^{\bot} &= span\left(\begin{bmatrix}
    -3 \\ -1 \\ 0 \\ 1 \\ 0
  \end{bmatrix},\begin{bmatrix}
    -4 \\ -3 \\ -2 \\ 0 \\ 1
  \end{bmatrix}\right)
\end{align*}

\begin{center}
  You can find all my notes at \url{http://omgimanerd.tech/notes}. If you have
  any questions, comments, or concerns, please contact me at
  alvin@omgimanerd.tech
\end{center}

\end{document}
